{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d396f43a-efe3-4c77-969b-1a6675bcea4b",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8a0205-8152-49ea-bdea-777c3ad00dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, Linear, to_hetero\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from src.utils import *\n",
    "from src.gnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5852b065-1f57-40bb-a903-eb84554f6665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f91937-8454-45e6-9090-71bf266ef8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6d603-ea2a-4c42-b953-bffc509d0a3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OWL2Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da76671-c06a-47da-b36c-8fecd439ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OWL2Bench_dbs = [{'path' : './datasets/OWL2Bench/OWL2Bench1/',\n",
    "                  'train_file' : '_train_OWL2Bench1',\n",
    "                  'test_file' : '_test_OWL2Bench1'},\n",
    "                 {'path' : './datasets/OWL2Bench/OWL2Bench2/',\n",
    "                  'train_file' : '_train_OWL2Bench2',\n",
    "                  'test_file' : '_test_OWL2Bench2'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a095d142-9c2f-4abd-a43e-087cc9b04dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_OWL2Bench1 _test_OWL2Bench1\n",
      "# Train - Triplets: 105, # Nodes/Classes: 113, # Edges: 105\n",
      "# Test - Triplets: 30, # Nodes/Classes: 45, # Edges: 30\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.4806\n",
      "Epoch: 50, Loss: 0.0795\n",
      "Epoch: 100, Loss: 0.0711\n",
      "Epoch: 150, Loss: 0.0632\n",
      "Epoch: 200, Loss: 0.0644\n",
      "Precision: 0.684, Recall: 0.433, F1-Score: 0.531\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.033, hits@10: 0.300, hits@100: 0.300\n",
      "\n",
      "\n",
      "Running... _train_OWL2Bench2 _test_OWL2Bench2\n",
      "# Train - Triplets: 105, # Nodes/Classes: 115, # Edges: 105\n",
      "# Test - Triplets: 30, # Nodes/Classes: 43, # Edges: 30\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.4984\n",
      "Epoch: 50, Loss: 0.0952\n",
      "Epoch: 100, Loss: 0.0689\n",
      "Epoch: 150, Loss: 0.0467\n",
      "Epoch: 200, Loss: 0.0383\n",
      "Precision: 0.724, Recall: 0.700, F1-Score: 0.712\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.067, hits@10: 0.300, hits@100: 0.300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in OWL2Bench_dbs:    \n",
    "    path = db_['path']\n",
    "    train_file = db_['train_file']\n",
    "    test_file = db_['test_file']\n",
    "\n",
    "    print('Running...', train_file, test_file)\n",
    "\n",
    "    df_train = load_ore_files(path+train_file)\n",
    "    df_train = df_train[df_train['p'] == 'SubClassOf']\n",
    "    g_train, nodes_train, edges_train = create_graph(df_train)\n",
    "    print(f'# Train - Triplets: {len(df_train)}, # Nodes/Classes: {g_train.number_of_nodes()}, # Edges: {g_train.number_of_edges()}')\n",
    "    df_test = load_ore_files(path+test_file)\n",
    "    df_test = df_test[df_test['p'] == 'SubClassOf']\n",
    "    g_test, nodes_test, edges_test = create_graph(df_test)\n",
    "    print(f'# Test - Triplets: {len(df_test)}, # Nodes/Classes: {g_test.number_of_nodes()}, # Edges: {g_test.number_of_edges()}')\n",
    "    print()\n",
    "\n",
    "    model = GNN()\n",
    "    model._train(g_train, 'GAT', 'Random Init')\n",
    "    model._eval(g_test, min(g_test.number_of_nodes(),100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0c1de-cb40-4bc5-a7fd-68fa1f51244f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab8ad86-ca50-4c24-8337-83b8c87c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE_dbs = [{'path' : './datasets/ORE/ORE1/',\n",
    "            'train_file' : '_train_ORE1',\n",
    "            'test_file' : '_test_ORE1'},\n",
    "           {'path' : './datasets/ORE/ORE2/',\n",
    "            'train_file' : '_train_ORE2',\n",
    "            'test_file' : '_test_ORE2'},\n",
    "           {'path' : './datasets/ORE/ORE3/',\n",
    "            'train_file' : '_train_ORE3',\n",
    "            'test_file' : '_test_ORE3'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0613db2-ccf6-4bb1-b306-534201a97593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_ORE1 _test_ORE1\n",
      "# Train - Triplets: 8194, # Nodes/Classes: 6654, # Edges: 8194\n",
      "# Test - Triplets: 2342, # Nodes/Classes: 3052, # Edges: 2342\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.3831\n",
      "Epoch: 50, Loss: 0.2063\n",
      "Epoch: 100, Loss: 0.1985\n",
      "Epoch: 150, Loss: 0.1954\n",
      "Epoch: 200, Loss: 0.1963\n",
      "Precision: 0.718, Recall: 0.518, F1-Score: 0.601\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.003, hits@10: 0.015, hits@100: 0.015\n",
      "\n",
      "\n",
      "Running... _train_ORE2 _test_ORE2\n",
      "# Train - Triplets: 8204, # Nodes/Classes: 6650, # Edges: 8204\n",
      "# Test - Triplets: 2344, # Nodes/Classes: 3102, # Edges: 2344\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.3822\n",
      "Epoch: 50, Loss: 0.2064\n",
      "Epoch: 100, Loss: 0.1989\n",
      "Epoch: 150, Loss: 0.1985\n",
      "Epoch: 200, Loss: 0.1926\n",
      "Precision: 0.678, Recall: 0.676, F1-Score: 0.677\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.003, hits@10: 0.014, hits@100: 0.014\n",
      "\n",
      "\n",
      "Running... _train_ORE3 _test_ORE3\n",
      "# Train - Triplets: 8187, # Nodes/Classes: 6673, # Edges: 8187\n",
      "# Test - Triplets: 2340, # Nodes/Classes: 3045, # Edges: 2340\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.3798\n",
      "Epoch: 50, Loss: 0.2052\n",
      "Epoch: 100, Loss: 0.2008\n",
      "Epoch: 150, Loss: 0.1978\n",
      "Epoch: 200, Loss: 0.1978\n",
      "Precision: 0.686, Recall: 0.527, F1-Score: 0.596\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.001, hits@10: 0.004, hits@100: 0.004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in ORE_dbs:    \n",
    "    path = db_['path']\n",
    "    train_file = db_['train_file']\n",
    "    test_file = db_['test_file']\n",
    "\n",
    "    print('Running...', train_file, test_file)\n",
    "\n",
    "    df_train = load_ore_files(path+train_file)\n",
    "    df_train = df_train[df_train['p'] == 'SubClassOf']\n",
    "    g_train, nodes_train, edges_train = create_graph(df_train)\n",
    "    print(f'# Train - Triplets: {len(df_train)}, # Nodes/Classes: {g_train.number_of_nodes()}, # Edges: {g_train.number_of_edges()}')\n",
    "    df_test = load_ore_files(path+test_file)\n",
    "    df_test = df_test[df_test['p'] == 'SubClassOf']\n",
    "    g_test, nodes_test, edges_test = create_graph(df_test)\n",
    "    print(f'# Test - Triplets: {len(df_test)}, # Nodes/Classes: {g_test.number_of_nodes()}, # Edges: {g_test.number_of_edges()}')\n",
    "    print()\n",
    "\n",
    "    model = GNN()\n",
    "    model._train(g_train, 'GAT', 'Random Init')\n",
    "    model._eval(g_test, min(g_test.number_of_nodes(),100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfa1d4-968b-4dd1-bb64-280b2186a08e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CaLiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa62032-1cb6-48d4-8fdf-e62cceece823",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLG_dbs = [{'path' : './datasets/clg/clg_10e4/',\n",
    "            'train_file' : 'clg_10e4-train.nt',\n",
    "            'test_file' : 'clg_10e4-test.nt'},\n",
    "           {'path' : './datasets/clg/clg_10e5/',\n",
    "            'train_file' : 'clg_10e5-train.nt',\n",
    "            'test_file' : 'clg_10e5-test.nt'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2805236-75e1-46dd-b6b0-d16d88b901b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... clg_10e4-train.nt clg_10e4-test.nt\n",
      "# Train - Triplets: 59956, # Nodes/Classes: 10311, # Edges: 59956\n",
      "# Test - Triplets: 17132, # Nodes/Classes: 7866, # Edges: 17132\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.2529\n",
      "Epoch: 50, Loss: 0.1712\n",
      "Epoch: 100, Loss: 0.1641\n",
      "Epoch: 150, Loss: 0.1616\n",
      "Epoch: 200, Loss: 0.1714\n",
      "Precision: 0.741, Recall: 0.651, F1-Score: 0.693\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.011, hits@10: 0.057, hits@100: 0.057\n",
      "\n",
      "\n",
      "Running... clg_10e5-train.nt clg_10e5-test.nt\n",
      "# Train - Triplets: 96273, # Nodes/Classes: 75195, # Edges: 96273\n",
      "# Test - Triplets: 27508, # Nodes/Classes: 26675, # Edges: 27508\n",
      "\n",
      "GAT + Random Init:\n",
      "Epoch: 0, Loss: 0.4921\n",
      "Epoch: 50, Loss: 0.1234\n",
      "Epoch: 100, Loss: 0.1134\n",
      "Epoch: 150, Loss: 0.1163\n",
      "Epoch: 200, Loss: 0.1144\n",
      "Precision: 0.848, Recall: 0.906, F1-Score: 0.876\n",
      "\n",
      "head, relation -> tail?\n",
      "hits@1: 0.014, hits@10: 0.080, hits@100: 0.080\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in CLG_dbs:\n",
    "    path = db_['path']\n",
    "    train_file = db_['train_file']\n",
    "    test_file = db_['test_file']\n",
    "\n",
    "    print('Running...', train_file, test_file)\n",
    "\n",
    "    df_train = load_clg_files(path+train_file)\n",
    "    df_train = df_train[df_train['p'] == '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    g_train, nodes_train, edges_train = create_graph(df_train)\n",
    "    print(f'# Train - Triplets: {len(df_train)}, # Nodes/Classes: {g_train.number_of_nodes()}, # Edges: {g_train.number_of_edges()}')\n",
    "    df_test = load_clg_files(path+test_file)\n",
    "    df_test = df_test[df_test['p'] == '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    g_test, nodes_test, edges_test = create_graph(df_test)\n",
    "    print(f'# Test - Triplets: {len(df_test)}, # Nodes/Classes: {g_test.number_of_nodes()}, # Edges: {g_test.number_of_edges()}')\n",
    "    print()\n",
    "\n",
    "    model = GNN()\n",
    "    model._train(g_train, 'GAT', 'Random Init')\n",
    "    model._eval(g_test, min(g_test.number_of_nodes(),100))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
